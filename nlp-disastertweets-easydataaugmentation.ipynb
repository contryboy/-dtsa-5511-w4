{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":17777,"databundleVersionId":869809,"sourceType":"competition"},{"sourceId":166220658,"sourceType":"kernelVersion"},{"sourceId":166308478,"sourceType":"kernelVersion"}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Summary\n\nThe target of the project is to create a supervised model with sequencial data deep learning model, to predict if a tweet indicates a real disaster. This is useful for some organizations to actively monitoring tweets for deteting disaster in near real time. ","metadata":{}},{"cell_type":"code","source":"import os\nimport re\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\nimport string\nimport pickle\nimport time\n\n\n# Import tqdm for progress bar\nfrom tqdm.notebook import tqdm\n","metadata":{"execution":{"iopub.status.busy":"2024-03-10T11:56:21.215493Z","iopub.execute_input":"2024-03-10T11:56:21.215837Z","iopub.status.idle":"2024-03-10T11:56:21.654051Z","shell.execute_reply.started":"2024-03-10T11:56:21.215815Z","shell.execute_reply":"2024-03-10T11:56:21.653121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from eda_util import eda","metadata":{"execution":{"iopub.status.busy":"2024-03-10T11:56:29.596836Z","iopub.execute_input":"2024-03-10T11:56:29.597948Z","iopub.status.idle":"2024-03-10T11:56:46.390043Z","shell.execute_reply.started":"2024-03-10T11:56:29.597911Z","shell.execute_reply":"2024-03-10T11:56:46.388557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_text = \"13,000 people receive #wildfires evacuation orders in California\"\neda(test_text,alpha_sr=0.3, alpha_ri=0, alpha_rs=0, p_rd=0, num_aug=4)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T12:11:54.186599Z","iopub.execute_input":"2024-03-10T12:11:54.187015Z","iopub.status.idle":"2024-03-10T12:11:54.195842Z","shell.execute_reply.started":"2024-03-10T12:11:54.186987Z","shell.execute_reply":"2024-03-10T12:11:54.194416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eda(test_text,alpha_sr=0, alpha_ri=0.3, alpha_rs=0, p_rd=0, num_aug=4)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T12:14:18.651749Z","iopub.execute_input":"2024-03-10T12:14:18.653140Z","iopub.status.idle":"2024-03-10T12:14:18.660920Z","shell.execute_reply.started":"2024-03-10T12:14:18.653094Z","shell.execute_reply":"2024-03-10T12:14:18.659849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load data","metadata":{}},{"cell_type":"code","source":"\ntrain_df=pickle.load(open(\"/kaggle/input/nlp-disastertweets-3-eda-cleaning/train_cleaned_df.pkl\", \"rb\"))\nprint(\"train data shape:\", train_df.shape)","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-03-10T12:06:41.682521Z","iopub.execute_input":"2024-03-10T12:06:41.682868Z","iopub.status.idle":"2024-03-10T12:06:41.713175Z","shell.execute_reply.started":"2024-03-10T12:06:41.682844Z","shell.execute_reply":"2024-03-10T12:06:41.712460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print some samples\nfor text in train_df.sample(n=5)[\"text\"].values:\n    print(\"original:\", text)\n    eda_text = eda(text,alpha_sr=0.3, alpha_ri=0, alpha_rs=0, p_rd=0, num_aug=5)\n    print(eda_text)\n    print(\"-------\")","metadata":{"execution":{"iopub.status.busy":"2024-03-10T12:07:08.174210Z","iopub.execute_input":"2024-03-10T12:07:08.174580Z","iopub.status.idle":"2024-03-10T12:07:08.211763Z","shell.execute_reply.started":"2024-03-10T12:07:08.174550Z","shell.execute_reply":"2024-03-10T12:07:08.210492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Translate and back","metadata":{}},{"cell_type":"code","source":"eda_sr_text_list = []\neda_ri_text_list = []\neda_rs_text_list = []\neda_rd_text_list = []\n\nfor idx, text in enumerate(train_df[\"text\"].values):\n    if idx%1000 == 0:\n        print(idx, \"/\", len(train_df))\n        \n    eda_sr_text_list.append(eda(text,alpha_sr=0.3, alpha_ri=0, alpha_rs=0, p_rd=0, num_aug=5))\n    eda_ri_text_list.append(eda(text,alpha_sr=0, alpha_ri=0.3, alpha_rs=0, p_rd=0, num_aug=5))\n    eda_rs_text_list.append(eda(text,alpha_sr=0, alpha_ri=0, alpha_rs=0.3, p_rd=0, num_aug=5))\n    eda_rd_text_list.append(eda(text,alpha_sr=0, alpha_ri=0, alpha_rs=0, p_rd=0.3, num_aug=5))\n    \n\npickle.dump(eda_sr_text_list, open(\"eda_sr_text_list.pkl\", \"wb\"))\npickle.dump(eda_ri_text_list, open(\"eda_ri_text_list.pkl\", \"wb\"))\npickle.dump(eda_rs_text_list, open(\"eda_rs_text_list.pkl\", \"wb\"))\npickle.dump(eda_rd_text_list, open(\"eda_rd_text_list.pkl\", \"wb\"))\n","metadata":{"execution":{"iopub.status.busy":"2024-03-10T13:07:18.691340Z","iopub.execute_input":"2024-03-10T13:07:18.691708Z","iopub.status.idle":"2024-03-10T13:07:31.897544Z","shell.execute_reply.started":"2024-03-10T13:07:18.691679Z","shell.execute_reply":"2024-03-10T13:07:31.896606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#eda_text_list_loaded = pickle.load(open(\"eda_text_list.pkl\", \"rb\"))\n#eda_text_list_loaded","metadata":{"execution":{"iopub.status.busy":"2024-03-10T12:14:30.038868Z","iopub.execute_input":"2024-03-10T12:14:30.039208Z","iopub.status.idle":"2024-03-10T12:14:30.043491Z","shell.execute_reply.started":"2024-03-10T12:14:30.039183Z","shell.execute_reply":"2024-03-10T12:14:30.042583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}